{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from funs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locally\n",
    "# data_url = 'https://github.com/dmika1234/ml_uwr_22/blob/Project/Project/data/fake_job_postings.csv'\n",
    "data_path = 'data/fake_job_postings.csv'\n",
    "raw_data = pd.read_csv(data_path)\n",
    "\n",
    "# For colab\n",
    "# data_url = '/content/fake_job_postings.csv'\n",
    "# raw_data = pd.read_csv(data_url, error_bad_lines=False, engine=\"python\")\n",
    "#straszny problem miałem, żeby wczytać te dane tak ja ty to robiłeś. dziwne błędy mi wyskakiwały"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dmika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dmika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\dmika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "text_colnames = ['company_profile', 'description', 'requirements', 'benefits']\n",
    "DataPrep = DataPreprocessor()\n",
    "\n",
    "text_data_ls = DataPrep.preprocess_data(text_data=raw_data, column_names=text_colnames, vectorize_fun=list)\n",
    "text_data_np = DataPrep.preprocess_data(text_data=raw_data, column_names=text_colnames, vectorize_fun=np.array)\n",
    "text_data_str = DataPrep.preprocess_data(text_data=raw_data, column_names=text_colnames, vectorize_fun=join_fun)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = raw_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Spliting location into country, state, city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df[['country', 'state', 'city']] = working_df['location'].str.split(',', expand=True).iloc[:,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Splitting salary range into min, max salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df[['salary_min', 'salary_max']] = working_df['salary_range'].str.split('-', expand=True)\n",
    "working_df[['salary_min', 'salary_max']] = working_df[['salary_min', 'salary_max']].apply(pd.to_numeric, errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['has_company_logo', 'telecommuting', 'has_questions', 'salary_min', 'salary_max']\n",
      "['company_profile', 'description', 'requirements', 'benefits']\n",
      "['required_experience', 'function', 'country', 'state', 'industry', 'title', 'employment_type', 'city', 'required_education', 'department']\n"
     ]
    }
   ],
   "source": [
    "target_colname = 'fraudulent'\n",
    "# Getting numerical colnames and deleting not useful\n",
    "numerical_colnames = list(working_df.select_dtypes(include='int64').columns)\n",
    "numerical_colnames = list(set(numerical_colnames) - set(['job_id', target_colname]))\n",
    "numerical_colnames = numerical_colnames + ['salary_min', 'salary_max']\n",
    "# Getting other text colnames and deleting not useful\n",
    "other_text_colnames = list(set(working_df.select_dtypes(include='object').columns) - set(text_colnames))\n",
    "other_text_colnames = list(set(other_text_colnames) - set(['location', 'salary_range']))\n",
    "print(numerical_colnames)\n",
    "print(text_colnames)\n",
    "print(other_text_colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df[text_colnames + other_text_colnames] = working_df[text_colnames + other_text_colnames].fillna('')\n",
    "working_df[numerical_colnames] = working_df[numerical_colnames].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employment_type            6\n",
       "required_experience        8\n",
       "required_education        14\n",
       "function                  38\n",
       "country                   91\n",
       "industry                 132\n",
       "state                    326\n",
       "department              1338\n",
       "city                    2336\n",
       "title                  11231\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df[other_text_colnames].apply(lambda x: np.unique(x).shape[0]).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will only use those with not so much levels(<50 for start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_other_text_colnames = ['employment_type', 'required_experience', 'required_education', 'function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employment_type_</th>\n",
       "      <th>employment_type_Contract</th>\n",
       "      <th>employment_type_Full-time</th>\n",
       "      <th>employment_type_Other</th>\n",
       "      <th>employment_type_Part-time</th>\n",
       "      <th>employment_type_Temporary</th>\n",
       "      <th>required_experience_</th>\n",
       "      <th>required_experience_Associate</th>\n",
       "      <th>required_experience_Director</th>\n",
       "      <th>required_experience_Entry level</th>\n",
       "      <th>...</th>\n",
       "      <th>function_Science</th>\n",
       "      <th>function_Strategy/Planning</th>\n",
       "      <th>function_Supply Chain</th>\n",
       "      <th>function_Training</th>\n",
       "      <th>function_Writing/Editing</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17875</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17878</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17879</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17880 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       employment_type_  employment_type_Contract  employment_type_Full-time  \\\n",
       "0                     0                         0                          0   \n",
       "1                     0                         0                          1   \n",
       "2                     1                         0                          0   \n",
       "3                     0                         0                          1   \n",
       "4                     0                         0                          1   \n",
       "...                 ...                       ...                        ...   \n",
       "17875                 0                         0                          1   \n",
       "17876                 0                         0                          1   \n",
       "17877                 0                         0                          1   \n",
       "17878                 0                         1                          0   \n",
       "17879                 0                         0                          1   \n",
       "\n",
       "       employment_type_Other  employment_type_Part-time  \\\n",
       "0                          1                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "...                      ...                        ...   \n",
       "17875                      0                          0   \n",
       "17876                      0                          0   \n",
       "17877                      0                          0   \n",
       "17878                      0                          0   \n",
       "17879                      0                          0   \n",
       "\n",
       "       employment_type_Temporary  required_experience_  \\\n",
       "0                              0                     0   \n",
       "1                              0                     0   \n",
       "2                              0                     1   \n",
       "3                              0                     0   \n",
       "4                              0                     0   \n",
       "...                          ...                   ...   \n",
       "17875                          0                     0   \n",
       "17876                          0                     0   \n",
       "17877                          0                     1   \n",
       "17878                          0                     0   \n",
       "17879                          0                     0   \n",
       "\n",
       "       required_experience_Associate  required_experience_Director  \\\n",
       "0                                  0                             0   \n",
       "1                                  0                             0   \n",
       "2                                  0                             0   \n",
       "3                                  0                             0   \n",
       "4                                  0                             0   \n",
       "...                              ...                           ...   \n",
       "17875                              0                             0   \n",
       "17876                              0                             0   \n",
       "17877                              0                             0   \n",
       "17878                              0                             0   \n",
       "17879                              0                             0   \n",
       "\n",
       "       required_experience_Entry level  ...  function_Science  \\\n",
       "0                                    0  ...                 0   \n",
       "1                                    0  ...                 0   \n",
       "2                                    0  ...                 0   \n",
       "3                                    0  ...                 0   \n",
       "4                                    0  ...                 0   \n",
       "...                                ...  ...               ...   \n",
       "17875                                0  ...                 0   \n",
       "17876                                0  ...                 0   \n",
       "17877                                0  ...                 0   \n",
       "17878                                0  ...                 0   \n",
       "17879                                0  ...                 0   \n",
       "\n",
       "       function_Strategy/Planning  function_Supply Chain  function_Training  \\\n",
       "0                               0                      0                  0   \n",
       "1                               0                      0                  0   \n",
       "2                               0                      0                  0   \n",
       "3                               0                      0                  0   \n",
       "4                               0                      0                  0   \n",
       "...                           ...                    ...                ...   \n",
       "17875                           0                      0                  0   \n",
       "17876                           0                      0                  0   \n",
       "17877                           0                      0                  0   \n",
       "17878                           0                      0                  0   \n",
       "17879                           0                      0                  0   \n",
       "\n",
       "       function_Writing/Editing  has_company_logo  telecommuting  \\\n",
       "0                             0                 1              0   \n",
       "1                             0                 1              0   \n",
       "2                             0                 1              0   \n",
       "3                             0                 1              0   \n",
       "4                             0                 1              0   \n",
       "...                         ...               ...            ...   \n",
       "17875                         0                 1              0   \n",
       "17876                         0                 1              0   \n",
       "17877                         0                 0              0   \n",
       "17878                         0                 0              0   \n",
       "17879                         0                 1              0   \n",
       "\n",
       "       has_questions  salary_min  salary_max  \n",
       "0                  0         0.0         0.0  \n",
       "1                  0         0.0         0.0  \n",
       "2                  0         0.0         0.0  \n",
       "3                  0         0.0         0.0  \n",
       "4                  1         0.0         0.0  \n",
       "...              ...         ...         ...  \n",
       "17875              1         0.0         0.0  \n",
       "17876              1         0.0         0.0  \n",
       "17877              0         0.0         0.0  \n",
       "17878              1         0.0         0.0  \n",
       "17879              1         0.0         0.0  \n",
       "\n",
       "[17880 rows x 71 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(working_df[final_other_text_colnames], columns=final_other_text_colnames)\n",
    "X[numerical_colnames] = working_df[numerical_colnames]\n",
    "y = working_df[target_colname]\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indcs, test_indcs = get_train_test_indcs(raw_data, raw_data['fraudulent'],\n",
    " test_size=.1, random_state=42, stratify=raw_data['fraudulent'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec for text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming company_profile data should take around 3.311111 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programy\\Anaconda3\\envs\\UniEnv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_profile data successfuly transformed!\n",
      "Transforming description data should take around 3.311111 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programy\\Anaconda3\\envs\\UniEnv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description data successfuly transformed!\n",
      "Transforming requirements data should take around 3.311111 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programy\\Anaconda3\\envs\\UniEnv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements data successfuly transformed!\n",
      "Transforming benefits data should take around 3.311111 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programy\\Anaconda3\\envs\\UniEnv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benefits data successfuly transformed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17880, 471)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_w2v = pd.DataFrame()\n",
    "for colname in text_colnames:\n",
    "    TxtTrans = TextTransformer(text_data_ls[colname][train_indcs], vector_size=100, min_count=1)\n",
    "    df_transformed = TxtTrans.transform_data(column_name=colname, data=text_data_ls[colname])\n",
    "    print(f'{colname} data successfuly transformed!')\n",
    "    X_w2v = pd.concat((X_w2v, df_transformed), axis=1)\n",
    "X_w2v.shape\n",
    "X_w2v_final = pd.concat((X, X_w2v), axis=1)\n",
    "X_w2v_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w2v.to_csv('data/X_w2v.csv', index=False)\n",
    "X_w2v = pd.read_csv('data/X_w2v.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w2v_train, X_w2v_test, y_train, y_test = X_w2v_final.iloc[train_indcs], X_w2v_final.iloc[test_indcs], y[train_indcs], y[test_indcs]\n",
    "\n",
    "clf_w2v = LogisticRegression(solver='liblinear', random_state=42, multi_class='ovr', max_iter=1000).fit(X_w2v_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic regression performence on TRAIN data:\n",
      " {'detection_percentage': 0.7086, 'precision': 0.0802, 'accuracy': 0.5927, 'f1_score': 0.1441, 'auc_roc': 0.6715}\n",
      "\n",
      "Logistic regression performence on TEST data: \n",
      "{'detection_percentage': 0.5977, 'precision': 0.0739, 'accuracy': 0.6158, 'f1_score': 0.1315, 'auc_roc': 0.6467}\n"
     ]
    }
   ],
   "source": [
    "y_proba = clf_w2v.predict_proba(X_w2v_train)[:, 1]\n",
    "res = evaluate_performance(y_train, y_proba, threshold=0.1)\n",
    "print(f'\\nLogistic regression performence on TRAIN data:\\n {res}')\n",
    "\n",
    "y_proba = clf_w2v.predict_proba(X_w2v_test)[:, 1]\n",
    "res = evaluate_performance(y_test, y_proba, threshold=0.1)\n",
    "print(f'\\nLogistic regression performence on TEST data: \\n{res}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_profile data successfuly transformed!\n",
      "description data successfuly transformed!\n",
      "requirements data successfuly transformed!\n",
      "benefits data successfuly transformed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17880, 271)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "number_of_vars = 50\n",
    "X_tfdif = pd.DataFrame()\n",
    "for colname in text_colnames:\n",
    "    vectorizer = TfidfVectorizer(max_features=number_of_vars, min_df=2).fit(text_data_str[colname][train_indcs])\n",
    "    df_transformed = pd.DataFrame(vectorizer.transform(text_data_str[colname]).toarray(), \n",
    "    columns=['num_' + colname + '_' + str(nr) for nr in np.arange(number_of_vars)])\n",
    "    print(f'{colname} data successfuly transformed!')\n",
    "    X_tfdif = pd.concat((X_tfdif, df_transformed), axis=1)\n",
    "X_tfdif.shape\n",
    "X_tfdif_final = pd.concat((X, X_tfdif), axis=1)\n",
    "X_tfdif_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tf_train, X_tf_test, y_train, y_test = X_tfdif_final.iloc[train_indcs], X_tfdif_final.iloc[test_indcs], y[train_indcs], y[test_indcs]\n",
    "\n",
    "clf_tf = LogisticRegression(solver='liblinear', random_state=42, multi_class='ovr', max_iter=1000).fit(X_tf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic regression performence on TRAIN data:\n",
      " {'detection_percentage': 0.611, 'precision': 0.1575, 'accuracy': 0.823, 'f1_score': 0.2504, 'auc_roc': 0.7621}\n",
      "\n",
      "Logistic regression performence on TEST data: \n",
      "{'detection_percentage': 0.5172, 'precision': 0.1385, 'accuracy': 0.8199, 'f1_score': 0.2185, 'auc_roc': 0.6673}\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.165\n",
    "y_proba = clf_tf.predict_proba(X_tf_train)[:, 1]\n",
    "res = evaluate_performance(y_train, y_proba, threshold=threshold)\n",
    "print(f'\\nLogistic regression performence on TRAIN data:\\n {res}')\n",
    "\n",
    "y_proba = clf_tf.predict_proba(X_tf_test)[:, 1]\n",
    "res = evaluate_performance(y_test, y_proba, threshold=threshold)\n",
    "print(f'\\nLogistic regression performence on TEST data: \\n{res}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleTextTransformer:\n",
    "    def __init__(self, path_to_model='GoogleNews-vectors-negative300.bin') -> None:\n",
    "        self.wv = KeyedVectors.load_word2vec_format(path_to_model, binary=True)\n",
    "        self.vector_size = self.wv.vector_size\n",
    "\n",
    "    def get_agg_word2vec(self, text, agg_func=np.mean):\n",
    "        # Get the word2vec representation of each word in the text\n",
    "        word_vectors = np.array([self.wv[word] for word in text if word in self.wv.index_to_key])\n",
    "        res = agg_func(word_vectors, axis=0)\n",
    "        if np.isnan(res).any():\n",
    "            res = np.zeros(self.vector_size)\n",
    "        return res\n",
    "\n",
    "    def transform_data(self, column_name, data=None, verbose=False):\n",
    "        n = data.shape[0]\n",
    "        if verbose:\n",
    "            print(f'Transforming {column_name} data should take around {(n / 90 / 60):3f} minutes')\n",
    "        X_train_vectors = data.apply(lambda x: self.get_agg_word2vec(x))\n",
    "        X_train_vectors = np.array(X_train_vectors)\n",
    "        X_train_vectors = np.vstack(X_train_vectors)\n",
    "        df_train = pd.DataFrame(X_train_vectors,\n",
    "         columns=['num_' + column_name + '_' + str(nr) for nr in np.arange(self.vector_size)])\n",
    "        self.data_transformed = df_train\n",
    "        return df_train   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programy\\Anaconda3\\envs\\UniEnv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_profile data successfuly transformed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programy\\Anaconda3\\envs\\UniEnv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description data successfuly transformed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programy\\Anaconda3\\envs\\UniEnv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements data successfuly transformed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programy\\Anaconda3\\envs\\UniEnv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benefits data successfuly transformed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17880, 1271)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ggl = pd.DataFrame()\n",
    "GglTxtTrans = GoogleTextTransformer()\n",
    "for colname in text_colnames:\n",
    "    df_transformed = GglTxtTrans.transform_data(column_name=colname, data=text_data_ls[colname])\n",
    "    df_transformed.to_csv('Ggl_'+ colname + '.csv', index=False)\n",
    "    print(f'{colname} data successfuly transformed!')\n",
    "    X_ggl = pd.concat((X_ggl, df_transformed), axis=1)\n",
    "X_ggl.to_csv('X_ggl_.csv', index=False)\n",
    "X_ggl.shape\n",
    "X_ggl_final = pd.concat((X, X_ggl), axis=1)\n",
    "X_ggl_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ggl = pd.read_csv('data/X_ggl.csv')\n",
    "X_ggl_final = pd.concat((X, X_ggl), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ggl_train, X_ggl_test, y_train, y_test = X_ggl_final.iloc[train_indcs], X_ggl_final.iloc[test_indcs], y[train_indcs], y[test_indcs]\n",
    "\n",
    "clf_ggl = LogisticRegression(solver='liblinear', random_state=42, multi_class='ovr', max_iter=1000).fit(X_ggl_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic regression performence on TRAIN data:\n",
      " {'detection_percentage': 0.6252, 'precision': 0.1537, 'accuracy': 0.8152, 'f1_score': 0.2467, 'auc_roc': 0.7549}\n",
      "\n",
      "Logistic regression performence on TEST data: \n",
      "{'detection_percentage': 0.5172, 'precision': 0.1316, 'accuracy': 0.8104, 'f1_score': 0.2098, 'auc_roc': 0.6498}\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.165\n",
    "y_proba = clf_ggl.predict_proba(X_ggl_train)[:, 1]\n",
    "res = evaluate_performance(y_train, y_proba, threshold=threshold)\n",
    "print(f'\\nLogistic regression performence on TRAIN data:\\n {res}')\n",
    "\n",
    "y_proba = clf_ggl.predict_proba(X_ggl_test)[:, 1]\n",
    "res = evaluate_performance(y_test, y_proba, threshold=threshold)\n",
    "print(f'\\nLogistic regression performence on TEST data: \\n{res}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fc72597e3ebe3b3cf4d5e7c9c96009b83c4c16e8afac821de511c3301abc35f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
